{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "quD0wavRs0"
   },
   "source": [
    "# Calculate evaluation metrics from training, validation, and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:08.704505Z",
     "iopub.status.busy": "2024-03-24T02:35:08.704398Z",
     "iopub.status.idle": "2024-03-24T02:35:09.088518Z",
     "shell.execute_reply": "2024-03-24T02:35:09.088060Z"
    },
    "jukit_cell_id": "RcnXoNLyM2"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "tdSJIClZGb"
   },
   "source": [
    "## Find the root of the git repo on the host system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.091003Z",
     "iopub.status.busy": "2024-03-24T02:35:09.090571Z",
     "iopub.status.idle": "2024-03-24T02:35:09.093475Z",
     "shell.execute_reply": "2024-03-24T02:35:09.093163Z"
    },
    "jukit_cell_id": "QmTyYX7yVG"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "eSQXraMRCI"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "cZx8xNCyZq"
   },
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.094983Z",
     "iopub.status.busy": "2024-03-24T02:35:09.094761Z",
     "iopub.status.idle": "2024-03-24T02:35:09.423632Z",
     "shell.execute_reply": "2024-03-24T02:35:09.423152Z"
    },
    "jukit_cell_id": "zFHiLC64Ss"
   },
   "outputs": [],
   "source": [
    "data_suf = \"log_reg_cp_fs_data_plate_5\"\n",
    "\n",
    "data_path = pathlib.Path(f\"{root_dir}/1.train_models/log_reg_plates_3_3p_5_cp_norm_data/data\")\n",
    "\n",
    "model_predf = pd.read_parquet(f\"{data_path}/model_data_{data_suf}.parquet\")\n",
    "evaldf = pd.read_parquet(f\"{data_path}/model_data_log_reg_cp_fs_data_plate_5.parquet\")\n",
    "le = load(f\"{data_path}/label_encoder_log_reg_cp_fs_data_plate_5.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "G0IEMyaFva"
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.426135Z",
     "iopub.status.busy": "2024-03-24T02:35:09.425740Z",
     "iopub.status.idle": "2024-03-24T02:35:09.428034Z",
     "shell.execute_reply": "2024-03-24T02:35:09.427703Z"
    },
    "jukit_cell_id": "byqT0qeQSc"
   },
   "outputs": [],
   "source": [
    "eval_path = pathlib.Path(\"model_eval_data\")\n",
    "eval_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.429374Z",
     "iopub.status.busy": "2024-03-24T02:35:09.429138Z",
     "iopub.status.idle": "2024-03-24T02:35:09.432315Z",
     "shell.execute_reply": "2024-03-24T02:35:09.431997Z"
    },
    "jukit_cell_id": "7K1U3LMO6u"
   },
   "outputs": [],
   "source": [
    "gene_column = \"true_genotype\"\n",
    "\n",
    "def down_sample_by_genotype(_df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas Dataframe\n",
    "        The data to be downsampled by the gene_column column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        The data down-sampled by genotype.\n",
    "    \"\"\"\n",
    "\n",
    "    min_gene = _df[gene_column].value_counts().min()\n",
    "    return (_df.groupby(gene_column, group_keys=False)\n",
    "            .apply(lambda x: x.sample(n=min_gene, random_state=0))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "idyVpjvE6c"
   },
   "source": [
    "## Calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.433699Z",
     "iopub.status.busy": "2024-03-24T02:35:09.433471Z",
     "iopub.status.idle": "2024-03-24T02:35:09.438160Z",
     "shell.execute_reply": "2024-03-24T02:35:09.437824Z"
    },
    "jukit_cell_id": "l12u5TJUQx"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "eval_mets = {\n",
    "    met: defaultdict(list) for met in\n",
    "    (\"f1_score\", \"precision_recall\", \"confusion_matrix\")\n",
    "}\n",
    "\n",
    "# Labels of confusion matrices in dataframe\n",
    "cm_true_labels = [\n",
    "    le.classes_[0],\n",
    "    le.classes_[0],\n",
    "    le.classes_[1],\n",
    "    le.classes_[1]\n",
    "]\n",
    "\n",
    "cm_pred_labels = [\n",
    "    le.classes_[0],\n",
    "    le.classes_[1],\n",
    "    le.classes_[0],\n",
    "    le.classes_[1]\n",
    "]\n",
    "\n",
    "def compute_metrics(_df, _plate, _split):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas Dataframe\n",
    "        Model data to be evaluated.\n",
    "\n",
    "    _plate: String\n",
    "        Name of the plate for storing the metrics\n",
    "\n",
    "    _split: String\n",
    "        Name of the data split for storing the metric\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = _df[gene_column]\n",
    "    y_pred = _df[\"predicted_genotype\"]\n",
    "    y_proba = _df[\"probability_WT\"]\n",
    "\n",
    "    # Store f1 scores\n",
    "    eval_mets[\"f1_score\"][\"f1_score\"].append(f1_score(y_true, y_pred))\n",
    "    eval_mets[\"f1_score\"][\"plate\"].append(_plate)\n",
    "    eval_mets[\"f1_score\"][\"datasplit\"].append(_split)\n",
    "\n",
    "    # Store precision and recall data\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    pr_size = precision.shape[0]\n",
    "    eval_mets[\"precision_recall\"][\"precision\"].extend(precision.tolist())\n",
    "    eval_mets[\"precision_recall\"][\"recall\"].extend(recall.tolist())\n",
    "    eval_mets[\"precision_recall\"][\"plate\"].extend([_plate] * pr_size)\n",
    "    eval_mets[\"precision_recall\"][\"datasplit\"].extend([_split] * pr_size)\n",
    "\n",
    "    # Store confusion matrices\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.flatten()\n",
    "    cm_size = cm.shape[0]\n",
    "    eval_mets[\"confusion_matrix\"][\"confusion_values\"].extend(cm.tolist())\n",
    "    eval_mets[\"confusion_matrix\"][\"true_genotype\"].extend(cm_true_labels)\n",
    "    eval_mets[\"confusion_matrix\"][\"predicted_genotype\"].extend(cm_pred_labels)\n",
    "    eval_mets[\"confusion_matrix\"][\"plate\"].extend([_plate] * cm_size)\n",
    "    eval_mets[\"confusion_matrix\"][\"datasplit\"].extend([_split] * cm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:09.439399Z",
     "iopub.status.busy": "2024-03-24T02:35:09.439174Z",
     "iopub.status.idle": "2024-03-24T02:35:17.557044Z",
     "shell.execute_reply": "2024-03-24T02:35:17.556492Z"
    },
    "jukit_cell_id": "GGD1QwPX1B"
   },
   "outputs": [],
   "source": [
    "# Iterate through each data split\n",
    "for split in evaldf[\"datasplit\"].unique():\n",
    "\n",
    "    # Calculate metrics for all plates\n",
    "    df_temp = evaldf.loc[(evaldf[\"datasplit\"] == split)].copy()\n",
    "    compute_metrics(df_temp, \"all_plates\", split)\n",
    "\n",
    "    # Calculate metrics for each plate\n",
    "    for plate in evaldf[\"plate\"].unique():\n",
    "        df_temp = evaldf.loc[(evaldf[\"plate\"] == plate) & (evaldf[\"datasplit\"] == split)].copy()\n",
    "        df_temp = down_sample_by_genotype(df_temp)\n",
    "        compute_metrics(df_temp, plate, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "EcFFCieEIm"
   },
   "source": [
    "### Save evaluation metrics for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T02:35:17.559264Z",
     "iopub.status.busy": "2024-03-24T02:35:17.558978Z",
     "iopub.status.idle": "2024-03-24T02:35:20.719011Z",
     "shell.execute_reply": "2024-03-24T02:35:20.718391Z"
    },
    "jukit_cell_id": "zubg81WM3n"
   },
   "outputs": [],
   "source": [
    "for met, met_data in eval_mets.items():\n",
    "    pd.DataFrame(eval_mets[met]).to_parquet(f\"{eval_path}/plate_{met}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
