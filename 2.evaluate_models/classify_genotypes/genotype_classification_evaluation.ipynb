{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "quD0wavRs0"
   },
   "source": [
    "# Calculate evaluation Plate and Datasplit evaluation results\n",
    "Evaluation results include confusion matrices, pr curves, precision, recall, f1-score, and accuracy.\n",
    "This occurs for each plate across all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:43.441371Z",
     "iopub.status.busy": "2024-05-28T15:18:43.441273Z",
     "iopub.status.idle": "2024-05-28T15:18:43.881204Z",
     "shell.execute_reply": "2024-05-28T15:18:43.880752Z"
    },
    "jukit_cell_id": "RcnXoNLyM2"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "tdSJIClZGb"
   },
   "source": [
    "## Find the root of the git repo on the host system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:43.883371Z",
     "iopub.status.busy": "2024-05-28T15:18:43.883164Z",
     "iopub.status.idle": "2024-05-28T15:18:43.885951Z",
     "shell.execute_reply": "2024-05-28T15:18:43.885633Z"
    },
    "jukit_cell_id": "QmTyYX7yVG"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = pathlib.Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "eSQXraMRCI"
   },
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "cZx8xNCyZq"
   },
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:43.887510Z",
     "iopub.status.busy": "2024-05-28T15:18:43.887238Z",
     "iopub.status.idle": "2024-05-28T15:18:46.028279Z",
     "shell.execute_reply": "2024-05-28T15:18:46.027699Z"
    },
    "jukit_cell_id": "zFHiLC64Ss"
   },
   "outputs": [],
   "source": [
    "data_path = pathlib.Path(f\"{root_dir}/1.train_models/classify_genotypes/data\")\n",
    "\n",
    "evaldf = pd.read_parquet(f\"{data_path}/nf1_model_pre_evaluation_results.parquet\")\n",
    "model = load(f\"{data_path}/trained_nf1_model.joblib\")\n",
    "le = load(f\"{data_path}/trained_nf1_model_label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "G0IEMyaFva"
   },
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:46.030507Z",
     "iopub.status.busy": "2024-05-28T15:18:46.030240Z",
     "iopub.status.idle": "2024-05-28T15:18:46.032567Z",
     "shell.execute_reply": "2024-05-28T15:18:46.032188Z"
    },
    "jukit_cell_id": "byqT0qeQSc"
   },
   "outputs": [],
   "source": [
    "eval_path = pathlib.Path(\"model_evaluation_data\")\n",
    "eval_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:46.033936Z",
     "iopub.status.busy": "2024-05-28T15:18:46.033729Z",
     "iopub.status.idle": "2024-05-28T15:18:46.036279Z",
     "shell.execute_reply": "2024-05-28T15:18:46.035949Z"
    },
    "jukit_cell_id": "7K1U3LMO6u"
   },
   "outputs": [],
   "source": [
    "gene_column = \"true_genotype\"\n",
    "\n",
    "def down_sample_by_genotype(_df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas Dataframe\n",
    "        The data to be downsampled by the gene_column column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        The data down-sampled by genotype.\n",
    "    \"\"\"\n",
    "\n",
    "    min_gene = _df[gene_column].value_counts().min()\n",
    "    return (_df.groupby(gene_column, group_keys=False)\n",
    "            .apply(lambda x: x.sample(n=min_gene, random_state=0))\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "idyVpjvE6c"
   },
   "source": [
    "## Calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:46.037654Z",
     "iopub.status.busy": "2024-05-28T15:18:46.037467Z",
     "iopub.status.idle": "2024-05-28T15:18:46.042660Z",
     "shell.execute_reply": "2024-05-28T15:18:46.042299Z"
    },
    "jukit_cell_id": "l12u5TJUQx"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metric data\n",
    "# The \"metrics\" include precision, recall, accuracy, and f1 scores\n",
    "eval_mets = {\n",
    "    met: defaultdict(list) for met in\n",
    "    (\"metrics\", \"precision_recall\", \"confusion_matrix\")\n",
    "}\n",
    "\n",
    "# Labels of confusion matrices in dataframe\n",
    "cm_true_labels = [\n",
    "    le.classes_[0],\n",
    "    le.classes_[0],\n",
    "    le.classes_[1],\n",
    "    le.classes_[1]\n",
    "]\n",
    "\n",
    "cm_pred_labels = [\n",
    "    le.classes_[0],\n",
    "    le.classes_[1],\n",
    "    le.classes_[0],\n",
    "    le.classes_[1]\n",
    "]\n",
    "\n",
    "def compute_metrics(_df, _plate, _split):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    _df: Pandas Dataframe\n",
    "        Model data to be evaluated.\n",
    "\n",
    "    _plate: String\n",
    "        Name of the plate for storing the metrics\n",
    "\n",
    "    _split: String\n",
    "        Name of the data split for storing the metric\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = _df[gene_column]\n",
    "    y_pred = _df[\"predicted_genotype\"]\n",
    "    y_proba = _df[\"probability_WT\"]\n",
    "\n",
    "    # Store metrics\n",
    "    eval_mets[\"metrics\"][\"f1_score\"].append(f1_score(y_true, y_pred))\n",
    "    eval_mets[\"metrics\"][\"precision\"].append(precision_score(y_true, y_pred))\n",
    "    eval_mets[\"metrics\"][\"recall\"].append(recall_score(y_true, y_pred))\n",
    "    eval_mets[\"metrics\"][\"accuracy\"].append(accuracy_score(y_true, y_pred))\n",
    "    eval_mets[\"metrics\"][\"plate\"].append(_plate)\n",
    "    eval_mets[\"metrics\"][\"datasplit\"].append(_split)\n",
    "\n",
    "    # Store precision and recall data\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    pr_size = precision.shape[0]\n",
    "    eval_mets[\"precision_recall\"][\"precision\"].extend(precision.tolist())\n",
    "    eval_mets[\"precision_recall\"][\"recall\"].extend(recall.tolist())\n",
    "    eval_mets[\"precision_recall\"][\"plate\"].extend([_plate] * pr_size)\n",
    "    eval_mets[\"precision_recall\"][\"datasplit\"].extend([_split] * pr_size)\n",
    "\n",
    "    # Store confusion matrices\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.flatten()\n",
    "    cm_size = cm.shape[0]\n",
    "    eval_mets[\"confusion_matrix\"][\"confusion_values\"].extend(cm.tolist())\n",
    "    eval_mets[\"confusion_matrix\"][\"true_genotype\"].extend(cm_true_labels)\n",
    "    eval_mets[\"confusion_matrix\"][\"predicted_genotype\"].extend(cm_pred_labels)\n",
    "    eval_mets[\"confusion_matrix\"][\"plate\"].extend([_plate] * cm_size)\n",
    "    eval_mets[\"confusion_matrix\"][\"datasplit\"].extend([_split] * cm_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:18:46.044014Z",
     "iopub.status.busy": "2024-05-28T15:18:46.043822Z",
     "iopub.status.idle": "2024-05-28T15:20:02.836630Z",
     "shell.execute_reply": "2024-05-28T15:20:02.836080Z"
    },
    "jukit_cell_id": "GGD1QwPX1B"
   },
   "outputs": [],
   "source": [
    "# Iterate through each data split\n",
    "for split in evaldf[\"datasplit\"].unique():\n",
    "\n",
    "    # Calculate metrics for all plates\n",
    "    df_temp = evaldf.loc[(evaldf[\"datasplit\"] == split)].copy()\n",
    "    compute_metrics(df_temp, \"all_plates\", split)\n",
    "\n",
    "    # Calculate metrics for each plate\n",
    "    for plate in evaldf[\"Metadata_Plate\"].unique():\n",
    "        df_temp = evaldf.loc[(evaldf[\"Metadata_Plate\"] == plate) & (evaldf[\"datasplit\"] == split)].copy()\n",
    "        df_temp = down_sample_by_genotype(df_temp)\n",
    "        compute_metrics(df_temp, plate, split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "EcFFCieEIm"
   },
   "source": [
    "### Save evaluation metrics and model coefficients for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T15:20:02.839758Z",
     "iopub.status.busy": "2024-05-28T15:20:02.839593Z",
     "iopub.status.idle": "2024-05-28T15:20:15.664973Z",
     "shell.execute_reply": "2024-05-28T15:20:15.664485Z"
    },
    "jukit_cell_id": "zubg81WM3n"
   },
   "outputs": [],
   "source": [
    "for met, met_data in eval_mets.items():\n",
    "    pd.DataFrame(eval_mets[met]).to_parquet(f\"{eval_path}/{met}.parquet\")\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"feature_names\": model.feature_names_in_,\n",
    "        \"feature_importances\": model.coef_.reshape(-1)\n",
    "    }\n",
    ").to_parquet(f\"{eval_path}/feature_importances.parquet\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
