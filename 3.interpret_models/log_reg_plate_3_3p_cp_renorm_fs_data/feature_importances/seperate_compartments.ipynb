{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "vk3QsHOEjG"
   },
   "source": [
    "# Here the features are seperated according to compartments for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "SyZ3qa8iz3"
   },
   "source": [
    "# %%--%%| <qGnYViiwRD|SyZ3qa8iz3>\n",
    "r\"\"\"°°°\n",
    "## Imports\n",
    "°°°\"\"\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n"
    },
    {
     "output_type": "execute_result",
     "execution_count": 1,
     "data": {
      "text/plain": "'°°°\\n## Imports\\n°°°'"
     },
     "metadata": {}
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "FKd1dIo45E"
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "ItCxTfECNg"
   },
   "source": [
    "## Find the git root Directory"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "zjh0SKYFgl"
   },
   "source": [
    "# Get the current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "OTkUmqTBVt"
   },
   "source": [
    "## Create the output path if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "W8zS6OpdNq"
   },
   "source": [
    "output_path = Path(\"data\")\n",
    "feature_file = \"feature_importances.tsv\"\n",
    "\n",
    "output_path.mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ")  # Create the parent directories if they don't exist"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "KChOdgSroB"
   },
   "source": [
    "## Import the model data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "aYwhtTNAgx"
   },
   "source": [
    "feature_properties = pd.read_csv(output_path / feature_file, sep=\"\\t\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "QmPiNYcAdw"
   },
   "source": [
    "## Seperate cell data by channel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "wSEsy3OWnz"
   },
   "source": [
    "# A map for comparments to channel\n",
    "compartment2channel = {\"actin\": \"RFP\", \"er\": \"GFP\", \"nucleus\": \"DAPI\"}\n",
    "\n",
    "# Create a Dictionary to hold the comparment data as dataframes\n",
    "compartment_data = {\n",
    "    compartment: feature_properties[feature_properties[\"feature\"].str.contains(channel)]\n",
    "    for compartment, channel in compartment2channel.items()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "hAmkVoVyDd"
   },
   "source": [
    "## Find the features that use more than one compartment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "CQscjFvYen"
   },
   "source": [
    "# Create a list of all possible comparment pairs\n",
    "pairs = list(itertools.combinations(compartment_data.keys(), 2))\n",
    "\n",
    "# Use a list of possible compartments for find compartment agnostic features\n",
    "pos_compartments = list(compartment2channel.values())\n",
    "\n",
    "# Get the features that do not belong to any compartment specifically\n",
    "other_compartment = feature_properties[\n",
    "    ~feature_properties[\"feature\"].str.contains(\"|\".join(pos_compartments))\n",
    "]\n",
    "\n",
    "# Find intersected rows between each pair of compartments\n",
    "for pair in pairs:\n",
    "    # Create placeholder dataframes for each comparment in the pair\n",
    "    df1 = compartment_data[pair[0]]\n",
    "    df2 = compartment_data[pair[1]]\n",
    "\n",
    "    # Get duplicate features between the two compartment dataframes\n",
    "    intersection = pd.concat([df1, df2], axis=0)\n",
    "    intersection = intersection[intersection.duplicated(subset=\"feature\", keep=False)]\n",
    "\n",
    "    # Remove any duplicate features already added to the other compartment dataframe\n",
    "    other_compartment = pd.concat([other_compartment, intersection], axis=0)\n",
    "    other_compartment = other_compartment.drop_duplicates(subset=\"feature\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "UwxezzhMqY"
   },
   "source": [
    "## Organize the data according to compartment in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "iTJOXFvhuT"
   },
   "source": [
    "# Remove features from each compartment dataframe if they are duplicates in other dataframes, or if the features only exist in the other_compartment dataframe\n",
    "compartment_data = {\n",
    "    compartment: compartment_data[compartment][\n",
    "        ~compartment_data[compartment][\"feature\"].isin(other_compartment[\"feature\"])\n",
    "    ]\n",
    "    for compartment, channel in compartment2channel.items()\n",
    "}\n",
    "\n",
    "compartment_data[\"other\"] = other_compartment\n",
    "\n",
    "# Create a compartment column for each comparment dataframe\n",
    "for compartment, df in compartment_data.items():\n",
    "    compartment_data[compartment][\"compartment\"] = len(df) * [compartment]\n",
    "\n",
    "# Concatenate the rows of DataFrames to create the plot\n",
    "concatenated_df = pd.concat(compartment_data.values(), ignore_index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "NtZG4xLsob"
   },
   "source": [
    "## Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jukit_cell_id": "NUwlraBlOz"
   },
   "source": [
    "concatenated_df.to_csv(output_path / \"feature_compartments.tsv\", sep=\"\\t\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
