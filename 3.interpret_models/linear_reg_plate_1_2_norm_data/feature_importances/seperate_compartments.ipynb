{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "vk3QsHOEjG"
   },
   "source": [
    "# Here the features are seperated according to compartments for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.759159Z",
     "iopub.status.busy": "2023-06-16T22:25:18.759051Z",
     "iopub.status.idle": "2023-06-16T22:25:18.764784Z",
     "shell.execute_reply": "2023-06-16T22:25:18.764461Z"
    },
    "jukit_cell_id": "SyZ3qa8iz3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'°°°\\n## Imports\\n°°°'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%--%%| <qGnYViiwRD|SyZ3qa8iz3>\n",
    "r\"\"\"°°°\n",
    "## Imports\n",
    "°°°\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.766292Z",
     "iopub.status.busy": "2023-06-16T22:25:18.766075Z",
     "iopub.status.idle": "2023-06-16T22:25:18.936627Z",
     "shell.execute_reply": "2023-06-16T22:25:18.936184Z"
    },
    "jukit_cell_id": "FKd1dIo45E"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "ItCxTfECNg"
   },
   "source": [
    "## Finding the git root directory to reference paths on any system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.938290Z",
     "iopub.status.busy": "2023-06-16T22:25:18.937957Z",
     "iopub.status.idle": "2023-06-16T22:25:18.940645Z",
     "shell.execute_reply": "2023-06-16T22:25:18.940279Z"
    },
    "jukit_cell_id": "zjh0SKYFgl"
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "if (cwd / \".git\").is_dir():\n",
    "    root_dir = cwd\n",
    "\n",
    "else:\n",
    "    root_dir = None\n",
    "    for parent in cwd.parents:\n",
    "        if (parent / \".git\").is_dir():\n",
    "            root_dir = parent\n",
    "            break\n",
    "\n",
    "# Check if a Git root directory was found\n",
    "if root_dir is None:\n",
    "    raise FileNotFoundError(\"No Git root directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "OTkUmqTBVt"
   },
   "source": [
    "## Create the output path if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.941916Z",
     "iopub.status.busy": "2023-06-16T22:25:18.941701Z",
     "iopub.status.idle": "2023-06-16T22:25:18.943850Z",
     "shell.execute_reply": "2023-06-16T22:25:18.943538Z"
    },
    "jukit_cell_id": "W8zS6OpdNq"
   },
   "outputs": [],
   "source": [
    "output_path = Path(\"data\")\n",
    "\n",
    "output_path.mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ")  # Create the parent directories if they don't exist\n",
    "\n",
    "sig_output_path = output_path / \"significant_feature_compartments.tsv\"\n",
    "output_path = output_path / \"feature_compartments.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "KChOdgSroB"
   },
   "source": [
    "## Import the model data as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.945264Z",
     "iopub.status.busy": "2023-06-16T22:25:18.944957Z",
     "iopub.status.idle": "2023-06-16T22:25:18.950039Z",
     "shell.execute_reply": "2023-06-16T22:25:18.949744Z"
    },
    "jukit_cell_id": "aYwhtTNAgx"
   },
   "outputs": [],
   "source": [
    "feature_properties = pd.read_csv(\n",
    "    root_dir\n",
    "    / \"1.train_models/linear_reg_plate_1_2_norm_data/data\"\n",
    "    / \"model_properties.tsv\",\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "QmPiNYcAdw"
   },
   "source": [
    "## Seperate cell data by channel\n",
    "\n",
    "We are analyzing the data according to compartment. To accomplish this we must group the data by compartment, where the channels of the image represent the compartments. However, in some cases, morphology features may use multiple channels, or no specific compartment channels. These features are considered apart of the \"other\" category in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.951352Z",
     "iopub.status.busy": "2023-06-16T22:25:18.951107Z",
     "iopub.status.idle": "2023-06-16T22:25:18.954874Z",
     "shell.execute_reply": "2023-06-16T22:25:18.954519Z"
    },
    "jukit_cell_id": "wSEsy3OWnz"
   },
   "outputs": [],
   "source": [
    "# A map for comparments to channel\n",
    "compartment2channel = {\"actin\": \"RFP\", \"er\": \"GFP\", \"nucleus\": \"DAPI\"}\n",
    "\n",
    "# Create a Dictionary to hold the comparment data as dataframes\n",
    "compartment_data = {\n",
    "    compartment: feature_properties[feature_properties[\"feature\"].str.contains(channel)]\n",
    "    for compartment, channel in compartment2channel.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "hAmkVoVyDd"
   },
   "source": [
    "## Find the features that use more than one compartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.956286Z",
     "iopub.status.busy": "2023-06-16T22:25:18.956075Z",
     "iopub.status.idle": "2023-06-16T22:25:18.962119Z",
     "shell.execute_reply": "2023-06-16T22:25:18.961789Z"
    },
    "jukit_cell_id": "CQscjFvYen"
   },
   "outputs": [],
   "source": [
    "# Create a list of all possible compartment pairs\n",
    "pairs = list(itertools.combinations(compartment_data.keys(), 2))\n",
    "\n",
    "# Use a list of possible compartments for find compartment agnostic features\n",
    "pos_compartments = list(compartment2channel.values())\n",
    "\n",
    "# Get the features that do not belong to any compartment specifically\n",
    "other_compartment = feature_properties[\n",
    "    ~feature_properties[\"feature\"].str.contains(\"|\".join(pos_compartments))\n",
    "]\n",
    "\n",
    "# Find intersected rows between each pair of compartments\n",
    "for pair in pairs:\n",
    "    # Create placeholder dataframes for each comparment in the pair\n",
    "    df1 = compartment_data[pair[0]]\n",
    "    df2 = compartment_data[pair[1]]\n",
    "\n",
    "    # Get duplicate features between the two compartment dataframes\n",
    "    intersection = pd.concat([df1, df2], axis=0)\n",
    "    intersection = intersection[intersection.duplicated(subset=\"feature\", keep=False)]\n",
    "\n",
    "    # Remove any duplicate features already added to the other compartment dataframe\n",
    "    other_compartment = pd.concat([other_compartment, intersection], axis=0)\n",
    "    other_compartment = other_compartment.drop_duplicates(subset=\"feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "UwxezzhMqY"
   },
   "source": [
    "## Organize the data according to compartment in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.963518Z",
     "iopub.status.busy": "2023-06-16T22:25:18.963263Z",
     "iopub.status.idle": "2023-06-16T22:25:18.967690Z",
     "shell.execute_reply": "2023-06-16T22:25:18.967364Z"
    },
    "jukit_cell_id": "iTJOXFvhuT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31715/1993350327.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compartment_data[compartment][\"compartment\"] = len(df) * [compartment]\n",
      "/tmp/ipykernel_31715/1993350327.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  compartment_data[compartment][\"compartment\"] = len(df) * [compartment]\n"
     ]
    }
   ],
   "source": [
    "# Remove features from each compartment dataframe if they are duplicates in other dataframes, or if the features only exist in the other_compartment dataframe\n",
    "compartment_data = {\n",
    "    compartment: compartment_data[compartment][\n",
    "        ~compartment_data[compartment][\"feature\"].isin(other_compartment[\"feature\"])\n",
    "    ]\n",
    "    for compartment, channel in compartment2channel.items()\n",
    "}\n",
    "\n",
    "compartment_data[\"other\"] = other_compartment\n",
    "\n",
    "# Create a compartment column for each comparment dataframe\n",
    "for compartment, df in compartment_data.items():\n",
    "    compartment_data[compartment][\"compartment\"] = len(df) * [compartment]\n",
    "\n",
    "# Concatenate the rows of DataFrames to create the plot below\n",
    "concatenated_df = pd.concat(compartment_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "NtZG4xLsob"
   },
   "source": [
    "## Save the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-16T22:25:18.969015Z",
     "iopub.status.busy": "2023-06-16T22:25:18.968812Z",
     "iopub.status.idle": "2023-06-16T22:25:18.984975Z",
     "shell.execute_reply": "2023-06-16T22:25:18.984671Z"
    },
    "jukit_cell_id": "NUwlraBlOz"
   },
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Define the critical threshold\n",
    "critical_threshold = concatenated_df[\"critical_threshold\"].iloc[0]\n",
    "\n",
    "# Create a dataframe with only significant models\n",
    "concatenated_df.loc[concatenated_df[\"corrected_p_value\"] <= critical_threshold].to_csv(\n",
    "    sig_output_path, sep=\"\\t\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
